---
- hosts: cluster
  vars_files:
    - vars/slurm.yaml
  become: yes
  tasks:

    - name: Stop slurmctld
      service:
        name: slurmctld      
        state: stopped
        enabled: no
      ignore_errors: yes
      tags: cleanup

    - name: Stop slurmd
      service:
        name: slurmd     
        state: stopped
        enabled: no
      tags: cleanup

    - name: Stop munge
      service:
        name: munge
        state: stopped
        enabled: no
      tags: cleanup      

    - name: Remove packages Centos
      yum:
        name: "{{ packages }}"
        state: absent
        update_cache: no
      vars:
        packages:
        - slurm-wlm
        - munge  
      when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
      tags: cleanup

    - name: Remove packages Ubuntu
      apt:
        name: "{{ packages }}"
        state: absent
        update_cache: no
      vars:
        packages:
        - slurm-wlm
        - munge
      when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
      tags: cleanup

    - name: delete slurm config if it exists
      file:
        path: "{{ item }}"
        state: absent
      with_items:
        - /etc/slurm-llnl
        - /var/run/slurm-llnl
        - /var/spool/slurm-lln
        - /etc/munge  
      tags: cleanup

    - name: Install packages Centos
      yum:
        name: "{{ packages }}"
        state: present
        update_cache: yes
      vars:
        packages:
        - chrony
        - atop
        - htop
        - netdata
        - irqbalance
        - slurm-wlm  
      when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
      tags: packages

    - name: Install packages Ubuntu
      apt:
        name: "{{ packages }}"
        state: present
        update_cache: yes
      vars:
        packages:
        - chrony
        - atop
        - htop
        - netdata
        - tuned
        - irqbalance
        - slurm-wlm  
      when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
      tags: packages

    - name: Ensure netdata is configured to listen on all IP's
      lineinfile:
        path: /etc/netdata/netdata.conf
        regexp: 'bind to = localhost'
        line:         bind to = {{ ansible_default_ipv4.address }}
      tags: packages

    - name: Restart netdata
      service:
        name: netdata
        state: restarted
        enabled: yes
      tags: packages

    - name: Ensure Chrony is running
      service:
        name: chronyd
        state: restarted
        enabled: yes
      ignore_errors: yes
      tags: packages

    - name: Stop and Disable Firewalld
      service:
        name: firewalld
        state: stopped
        enabled: no
      ignore_errors: yes

    - name: Disable SE Linux
      shell:
        cmd: /usr/sbin/setenforce 0
      register: command_result
      failed_when: "'ERROR' in command_result.stderr"
      ignore_errors: yes
      when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
      tags: prep

    - name: Disable SELinux permanently
      selinux:
        state: disabled
      when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
      tags: prep

    - name: Ensure Apparmor is stopped
      service:
        name: apparmor
        state: stopped
        enabled: no
      ignore_errors: yes
      when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
      tags: prep

    - name: Remove apparmor
      package:
        name: apparmor
        state: absent
      when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
      ignore_errors: yes
      tags: prep

    - name: Remove swaps from fstab
      lineinfile:
        dest: /etc/fstab
        regexp: '^/[\S]+\s+swap\s+swap'
        state: absent
      tags: tune

    - name: Disable swap
      shell:
        cmd: swapoff -a
      tags: tune

    - name: Ensure irqbalance is set to oneshot - Centos
      lineinfile:
        path: /etc/sysconfig/irqbalance
        regexp: '^#IRQBALANCE_ONESHOT='
        line: IRQBALANCE_ONESHOT=1
      when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
      tags: tune

    - name: Ensure irqbalance is set to oneshot - Ubuntu
      lineinfile:
        path: /etc/default/irqbalance
        regexp: '^#IRQBALANCE_ONESHOT='
        line: IRQBALANCE_ONESHOT=1
      when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
      tags: tune

    - name: Restart irqbalance
      service:
        name: irqbalance
        state: restarted
        enabled: yes
      tags: tune

    - name: Set tuned profile
      shell:
        cmd: tuned-adm profile throughput-performance
      tags: tune

    - name: Create and modify permissions spool directory
      file:
        path: /var/spool/slurm-llnl
        state: directory
        owner: slurm
        group: slurm
        mode: u=rwX,g=rX,o=rX
        recurse: yes

    - name: Create and modify permissions run directory
      file:
        path: /var/run/slurm-llnl
        state: directory
        recurse: yes
        owner: slurm
        group: slurm
        mode: 0755

    - name: Create and modify permissions run directory
      file:
        path: /etc/slurm-llnl
        state: directory
        recurse: yes
        owner: slurm
        group: slurm
        mode: 0755

    - name: create slurm config file
      file:
        path: /etc/slurm-llnl/slurm.conf
        state: touch
        owner: slurm
        group: slurm
        mode: 0755        

    - name: Configure slurm
      blockinfile:
        path: /etc/slurm-llnl/slurm.conf
        block: |
          ControlMachine="{{ CONTROLMACHINE }}"
          ControlAddr="{{ CONTROLADDR }}"
          MpiDefault=none
          ProctrackType=proctrack/pgid
          ReturnToService=2
          SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid
          SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid
          SlurmdSpoolDir=/var/spool/slurm-llnl
          SlurmUser=slurm
          #SlurmdUser=root
          StateSaveLocation=/var/spool/slurm-llnl
          SwitchType=switch/none
          TaskPlugin=task/none
          FastSchedule=0
          SchedulerType=sched/backfill
          SelectType=select/linear
          AccountingStorageType=accounting_storage/none
          ClusterName="{{ CLUSTERNAME }}"
          JobAcctGatherType=jobacct_gather/none
          NodeName="{{ NODENAME }}" NodeAddr="{{ NODEADDR }}" CPUs="{{ CPUS }}" RealMemory="{{ REALMEMORY }}" Sockets="{{ SOCKETS }}" CoresPerSocket="{{ CORESPERSOCKET }}" ThreadsPerCore="{{ THREADSPERCORE }}"  State=UNKNOWN
          PartitionName=debug Nodes="{{ NODES }}" Default=YES MaxTime=INFINITE State=UP
      tags: config

- hosts: controller
  vars_files:
    - vars/slurm.yaml
  become: yes
  tasks:  

    - name: Copy munge to local
      fetch:
        src: /etc/munge/munge.key
        dest: templates/
        flat: yes
        mode: preserve
      tags: services

    - name: Start munge
      systemd:
        name: munge
        state: restarted
        enabled: yes
        daemon_reload: yes
      tags: services

    - name: Start slurmctld
      systemd:
        name: slurmctld      
        state: restarted
        enabled: yes
        daemon_reload: yes
      tags: services

    - name: Start slurmd
      systemd:
        name: slurmd
        state: restarted
        enabled: yes
        daemon_reload: yes
      tags: services

- hosts: cluster,!controller
  vars_files:
    - vars/slurm.yaml
  become: yes
  tasks: 

    - name: Copy file with owner and permission
      copy:
        src: templates/munge.key
        dest: /etc/munge/
        owner: munge
        group: munge
        mode: a-r,u-w,u+r
        force: yes

    - name: Start munge
      systemd:
        name: munge
        state: restarted
        enabled: yes
        daemon_reload: yes
      tags: services

    - name: Start slurmctld
      systemd:
        name: slurmctld      
        state: stopped
        enabled: no
        daemon_reload: no
      tags: services

    - name: Start slurmd
      systemd:
        name: slurmd     
        state: restarted
        enabled: yes
        daemon_reload: yes
      tags: services
